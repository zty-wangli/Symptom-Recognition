{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer, load_vocab\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from bert4keras.snippets import to_array\n",
    "from keras.layers import Lambda\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "import fairies as fa\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "maxlen = 64\n",
    "batch_size = 48\n",
    "epochs = 40\n",
    "p = './bert_weight_file/uncased_L-4_H-256_A-4/'\n",
    "config_path = p + 'bert_config.json'\n",
    "checkpoint_path = p + 'bert_model.ckpt'\n",
    "dict_path = p + 'vocab.txt'\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "train_data = fa.read(\"train.json\")\n",
    "import random\n",
    "random.shuffle(train_data)\n",
    "\n",
    "valid_data = fa.read(\"dev.json\")\n",
    "\n",
    "token_dict, keep_tokens = load_vocab(\n",
    "    dict_path=dict_path,\n",
    "    simplified=True,\n",
    "    startswith=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, '23介肺炎疫苗有必要打吗', '永城市接种肺炎疫苗哪个医院好'],\n",
       " [0, '得了过敏性哮喘要注意些什么谢谢', '得了过敏性哮喘有什么症状'],\n",
       " [1, '变异性哮喘应该要注意什么', '患有变异性哮喘需要注意的地方有什么呢'],\n",
       " [0, '冠状病毒肺炎 血液检查', '血常规检查结果怎么样证明是肺炎'],\n",
       " [1, '23价肺炎疫苗的注射时间', '23价肺炎疫苗什么时候注射啊'],\n",
       " [0, '反复上呼吸道感染，什么原因导致', '上呼吸道感染 小孩反复发烧到底是什么原因'],\n",
       " [0, '阿奇霉素片注意事项有哪些', '阿奇霉素片得功效怎么样'],\n",
       " [1, '丰鹿牌百咳静糖浆是正品药吗', '丰鹿牌百咳静糖浆质量有保障吗'],\n",
       " [1, '月经期间吃感冒药物的影响是什么啊', '月经期间吃感冒药物对身体有哪些影响'],\n",
       " [0, '咳嗽变异性哮喘，是由什么原因造成的', '咳嗽变异性哮喘症状是什么']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        \"\"\"单条样本格式为\n",
    "            输入：[CLS]两句话意思[MASK]同,text1,text2[SEP]\n",
    "            输出：'相'或者'不'\n",
    "        \"\"\"\n",
    "        idxs = list(range(len(self.data)))\n",
    "        if random:\n",
    "            np.random.shuffle(idxs)\n",
    "        batch_token_ids, batch_segment_ids, batch_a_token_ids = [], [], []\n",
    "\n",
    "        for i in idxs:\n",
    "\n",
    "            data = self.data[i]\n",
    "            text = \"两句话意思相同\"\n",
    "            text1 = data[1]\n",
    "            text2 = data[2]\n",
    "            label = data[0]\n",
    "\n",
    "            final_text = text + ':' + text1 + ',' + text2\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                final_text, maxlen=maxlen)\n",
    "\n",
    "            # mask掉'相'字\n",
    "            token_ids[6] = tokenizer._token_mask_id\n",
    "\n",
    "            if label == 0:\n",
    "                a_token_ids, _ = tokenizer.encode('不')\n",
    "            else:\n",
    "                a_token_ids, _ = tokenizer.encode('相')\n",
    "\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_a_token_ids.append(a_token_ids[1:])\n",
    "\n",
    "            if len(batch_token_ids) == self.batch_size or i == idxs[-1]:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_a_token_ids = sequence_padding(batch_a_token_ids, 1)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_a_token_ids\n",
    "                batch_token_ids, batch_segment_ids, batch_a_token_ids = [], [], []\n",
    "\n",
    "\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.data_generator at 0x25e0d897548>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     multiple             7472896     Input-Token[0][0]                \n",
      "                                                                 MLM-Norm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 256)    512         Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 256)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 256)    131072      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 256)    512         Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 256)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 256)    263168      Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 256)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 256)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 256)    512         Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 256)    525568      Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 256)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 256)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 256)    512         Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 256)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 256)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 256)    512         Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 256)    525568      Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 256)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 256)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 256)    512         Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 256)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 256)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 256)    512         Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 256)    525568      Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 256)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 256)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 256)    512         Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 256)    263168      Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 256)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 256)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 256)    512         Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 256)    525568      Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 256)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 256)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 256)    512         Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, None, 256)    65792       Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, None, 256)    512         MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Bias (BiasAdd)              (None, None, 29191)  29191       Embedding-Token[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Activation (Activation)     (None, None, 29191)  0           MLM-Bias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 29191)  0           MLM-Activation[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 10,859,527\n",
      "Trainable params: 10,859,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/40\n",
      "  8/183 [>.............................] - ETA: 9:23 - loss: 9.8796 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-204f0c0bb58d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         callbacks=[evaluator])\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./best_model.weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        \"\"\"单条样本格式为\n",
    "            输入：[CLS]两句话意思[MASK]同,text1,text2[SEP]\n",
    "            输出：'相'或者'不'\n",
    "        \"\"\"\n",
    "        idxs = list(range(len(self.data)))\n",
    "        if random:\n",
    "            np.random.shuffle(idxs)\n",
    "        batch_token_ids, batch_segment_ids, batch_a_token_ids = [], [], []\n",
    "\n",
    "        for i in idxs:\n",
    "\n",
    "            data = self.data[i]\n",
    "            text = \"两句话意思相同\"\n",
    "            text1 = data[1]\n",
    "            text2 = data[2]\n",
    "            label = data[0]\n",
    "\n",
    "            final_text = text + ':' + text1 + ',' + text2\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                final_text, maxlen=maxlen)\n",
    "\n",
    "            # mask掉'相'字\n",
    "            token_ids[6] = tokenizer._token_mask_id\n",
    "\n",
    "            if label == 0:\n",
    "                a_token_ids, _ = tokenizer.encode('不')\n",
    "            else:\n",
    "                a_token_ids, _ = tokenizer.encode('相')\n",
    "\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_a_token_ids.append(a_token_ids[1:])\n",
    "\n",
    "            if len(batch_token_ids) == self.batch_size or i == idxs[-1]:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_a_token_ids = sequence_padding(batch_a_token_ids, 1)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_a_token_ids\n",
    "                batch_token_ids, batch_segment_ids, batch_a_token_ids = [], [], []\n",
    "\n",
    "\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)\n",
    "\n",
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    with_mlm=True,\n",
    "    keep_tokens=keep_tokens,  # 只保留keep_tokens中的字，精简原字表\n",
    ")\n",
    "\n",
    "output = Lambda(lambda x: x[:, 6:7])(model.output)\n",
    "model = Model(model.input, output)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "def masked_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"交叉熵作为loss，并mask掉padding部分的预测\n",
    "    \"\"\"\n",
    "    y_true = K.reshape(y_true, [K.shape(y_true)[0], -1])\n",
    "    y_mask = K.cast(K.not_equal(y_true, 0), K.floatx())\n",
    "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    cross_entropy = K.sum(cross_entropy * y_mask) / K.sum(y_mask)\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "model.compile(loss=masked_cross_entropy, optimizer=Adam(2e-5))\n",
    "\n",
    "\n",
    "def get_ngram_set(x, n):\n",
    "    \"\"\"生成ngram合集，返回结果格式是:\n",
    "    {(n-1)-gram: set([n-gram的第n个字集合])}\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for i in range(len(x) - n + 1):\n",
    "        k = tuple(x[i:i + n])\n",
    "        if k[:-1] not in result:\n",
    "            result[k[:-1]] = set()\n",
    "        result[k[:-1]].add(k[-1])\n",
    "    return result\n",
    "\n",
    "\n",
    "def predict(data):\n",
    "    \"\"\"\n",
    "        数据格式\n",
    "        text1 = data[0]\n",
    "        text2 = data[1]\n",
    "        label = data[2]\n",
    "        方便预测和训练时候评价\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text = \"两句话意思相同\"\n",
    "    text1 = data[1]\n",
    "    text2 = data[2]\n",
    "    label = data[0]\n",
    "\n",
    "    final_text = text + ':' + text1 + ',' + text2\n",
    "    token_ids, segment_ids = tokenizer.encode(final_text, maxlen=maxlen)\n",
    "\n",
    "    # mask掉'相'字\n",
    "    token_ids[6] = tokenizer._token_mask_id\n",
    "    token_ids, segment_ids = to_array([token_ids], [segment_ids])\n",
    "\n",
    "    # 用mlm模型预测被mask掉的部分\n",
    "    probas = model.predict([token_ids, segment_ids])[0]\n",
    "    res = tokenizer.decode(probas.argmax(axis=1))\n",
    "\n",
    "    if res == '不' and label == 0:\n",
    "        return '正确'\n",
    "    elif res == '相' and label == 1:\n",
    "        return '正确'\n",
    "    elif res != '不' and res != '相':\n",
    "        return '超出范围'\n",
    "    else:\n",
    "        return '错误'\n",
    "\n",
    "\n",
    "def evaluat_vail_data(valid_data):\n",
    "\n",
    "    right, out, all = 1, 1, 1\n",
    "\n",
    "    for valid in valid_data:\n",
    "        res = predict(valid)\n",
    "\n",
    "        if res == '正确':\n",
    "            right += 1\n",
    "        elif res == '超出范围':\n",
    "            out += 1\n",
    "\n",
    "        all += 1\n",
    "\n",
    "    return right / all, out\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lowest = 1e10\n",
    "        self.best = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # 保存最优\n",
    "        # if logs['loss'] <= self.lowest:\n",
    "        #     self.lowest = logs['loss']\n",
    "        #     model.save_weights('./best_model.weights')\n",
    "        acc, out = evaluat_vail_data(valid_data)\n",
    "        print(acc, out)\n",
    "        if acc >= self.best:\n",
    "            self.best = acc\n",
    "            model.save_weights('./best_model.weights')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    train_generator = data_generator(train_data, batch_size)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator.forfit(),\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        callbacks=[evaluator])\n",
    "\n",
    "    model.load_weights('./best_model.weights')\n",
    "    acc, out = evaluat_vail_data(valid_data)\n",
    "    print(acc)\n",
    "    print(out)\n",
    "    # 0.8981527708437343\n",
    "    # 0.9041437843235147\n",
    "else:\n",
    "\n",
    "    model.load_weights('./best_model.weights')\n",
    "    evaluat_vail_data(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
